{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 蔡沅珈 Tsai, Yuan-Chia\n",
    "\n",
    "Student ID: 109164503\n",
    "\n",
    "GitHub ID: 45623944\n",
    "\n",
    "Kaggle name: chuck\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2020-Lab2-Master Repo](https://github.com/fhcalderon87/DM2020-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/c/dm2020-hw2-nthu/) regarding Emotion Recognition on Twitter. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the score (ie. 20% of 30% )\n",
    "\n",
    "    - **Top 41% - 100%**: Get (101-x)% of the score, where x is your ranking in the leaderboard (ie. (101-x)% of 30% )   \n",
    "    Submit your last submission __BEFORE the deadline (Dec. 5th 11:59 pm, Saturday)__. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/fhcalderon87/DM2020-Lab1-Master/blob/master/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb), but make sure to fork the [DM2020-Lab2-Homework](https://github.com/fhcalderon87/DM2020-Lab2-Homework) repository this time! Also please __DON´T UPLOAD HUGE DOCUMENTS__, please use Git ignore for that.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Dec. 8th 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "X = train_df[\"text\"]\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(X)\n",
    "\n",
    "term_frequencies_X = []\n",
    "for j in range(0,X_counts.shape[1]):\n",
    "    term_frequencies_X.append(sum(X_counts[:,j].toarray()))\n",
    "    \n",
    "term_frequencies_X = np.asarray(X_counts.sum(axis=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_term_frequencies_X = term_frequencies_X[term_frequencies_X > 0]\n",
    "sort = np.argsort(-new_term_frequencies_X)\n",
    "plt.subplots(figsize=(50, 10))\n",
    "g = sns.barplot(x=np.asarray(count_vect.get_feature_names())[sort[:30]], \n",
    "            y=new_term_frequencies_X[sort[:30]])\n",
    "g.set_xticklabels(count_vect.get_feature_names()[:30], rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = test_df[\"text\"]\n",
    "count_vect = CountVectorizer()\n",
    "Y_counts = count_vect.fit_transform(Y)\n",
    "\n",
    "term_frequencies_Y = []\n",
    "for j in range(0,Y_counts.shape[1]):\n",
    "    term_frequencies_Y.append(sum(Y_counts[:,j].toarray()))\n",
    "    \n",
    "term_frequencies_Y = np.asarray(Y_counts.sum(axis=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_term_frequencies_Y = term_frequencies_Y[term_frequencies_Y > 0]\n",
    "sort = np.argsort(-new_term_frequencies_Y)\n",
    "plt.subplots(figsize=(50, 10))\n",
    "g = sns.barplot(x=np.asarray(count_vect.get_feature_names())[sort[:30]], \n",
    "            y=new_term_frequencies_Y[sort[:30]])\n",
    "g.set_xticklabels(count_vect.get_feature_names()[:30], rotation = 90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "TFIDF_vectorizer = TfidfVectorizer()\n",
    "\n",
    "TFIDF_vectorizer.fit(train_df['text'])\n",
    "\n",
    "TFIDF_1000 = TfidfVectorizer(max_features=1000, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "TFIDF_1000.fit(train_df['text'])\n",
    "\n",
    "train_data_TFIDF_features_1000 = TFIDF_1000.transform(train_df['text'])\n",
    "\n",
    "feature_names_TFIDF_1000 = TFIDF_1000.get_feature_names()\n",
    "feature_names_TFIDF_1000[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix can easily see which label predict right or wrong. For example, this model predict 110 result in fear, and 70 of them are right, as we can see the prediction target to sadness and anger are more than joy, which means the emotion fear is near than anger and sadness more. And we can see the prediction to fear is much more than others, which may have some way to improve this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X = BOW_500.transform(train_df['text'])\n",
    "y = train_df['emotion']\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "print(clf.predict(X[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the number of data attributes is large or the correlation between attributes is large, Decision Tree is better than Naive Bayes. When the correlation between attributes is small, Naive Bayes will perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_accuracy = training_log['accuracy']\n",
    "val_accuracy = training_log['val_accuracy']\n",
    "train_loss = training_log['loss']\n",
    "val_loss = training_log['val_loss']\n",
    "epochs_list = np.array(range(1,epochs + 1))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs_list, train_accuracy, 'b')\n",
    "plt.plot(epochs_list, val_accuracy, 'red')\n",
    "plt.title('Training accuracy per epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(('train_accuracy', 'val_accuracy'))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs_list, train_loss, 'b')\n",
    "plt.plot(epochs_list, val_loss, 'red')\n",
    "plt.title('Training loss per epoch')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(('train_loss', 'val_loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each sentence, there have some key words for us to determine which emotion it should be, like birthday usually connected with happy. But some of the words can't help us to determine the emotion. For example, \"I hate you\" and \"I love you\", these two sentences have \"I\" and \"you\", but the emotion are totally different. In this case, we can pick \"hate\" and \"love\" to represent two different emotion, we don't need the whole sentence to identify the emotion. We can use these key \"words\" to represent the sentence data and train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['angry', 'happy', 'sad', 'fear']\n",
    "\n",
    "topn = 15\n",
    "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]\n",
    "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]        \n",
    "sad_words = ['sad'] + [word_ for word_, sim_ in w2v_google_model.most_similar('sad', topn=topn)]        \n",
    "fear_words = ['fear'] + [word_ for word_, sim_ in w2v_google_model.most_similar('fear', topn=topn)]        \n",
    "\n",
    "print('angry_words: ', angry_words)\n",
    "print('happy_words: ', happy_words)\n",
    "print('sad_words: ', sad_words)\n",
    "print('fear_words: ', fear_words)\n",
    "\n",
    "target_words = angry_words + happy_words + sad_words + fear_words\n",
    "print('\\ntarget words: ')\n",
    "print(target_words)\n",
    "\n",
    "print('\\ncolor list:')\n",
    "cn = topn + 1\n",
    "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
    "print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model = w2v_google_model\n",
    "\n",
    "size = 200\n",
    "target_size = len(target_words)\n",
    "all_word = list(model.vocab.keys())\n",
    "word_train = target_words + all_word[:size]\n",
    "X_train = model[word_train]\n",
    "\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=28)\n",
    "\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
    "plt.scatter(X_tsne[:target_size, 0], X_tsne[:target_size, 1], c=color)\n",
    "for label, x, y in zip(target_words, X_tsne[:target_size, 0], X_tsne[:target_size, 1]):\n",
    "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1867535\n"
     ]
    }
   ],
   "source": [
    "# import json data\n",
    "file = open(\"tweets_DM.json\", 'r', encoding='utf-8')\n",
    "data = []\n",
    "for line in file.readlines():\n",
    "    dic = json.loads(line)\n",
    "    data.append(dic)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_score': 391,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': ['Snapchat'],\n",
       "    'tweet_id': '0x376b20',\n",
       "    'text': 'People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that\\'s <LH>'}},\n",
       "  '_crawldate': '2015-05-23 11:42:47',\n",
       "  '_type': 'tweets'},\n",
       " {'_score': 433,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': ['freepress', 'TrumpLegacy', 'CNN'],\n",
       "    'tweet_id': '0x2d5350',\n",
       "    'text': '@brianklaas As we see, Trump is dangerous to #freepress around the world. What a <LH> <LH> #TrumpLegacy.  #CNN'}},\n",
       "  '_crawldate': '2016-01-28 04:52:09',\n",
       "  '_type': 'tweets'},\n",
       " {'_score': 232,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': ['bibleverse'],\n",
       "    'tweet_id': '0x28b412',\n",
       "    'text': 'Confident of your obedience, I write to you, knowing that you will do even more than I ask. (Philemon 1:21) 3/4 #bibleverse <LH> <LH>'}},\n",
       "  '_crawldate': '2017-12-25 04:39:20',\n",
       "  '_type': 'tweets'},\n",
       " {'_score': 376,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': [],\n",
       "    'tweet_id': '0x1cd5b0',\n",
       "    'text': 'Now ISSA is stalking Tasha 😂😂😂 <LH>'}},\n",
       "  '_crawldate': '2016-01-24 23:53:05',\n",
       "  '_type': 'tweets'},\n",
       " {'_score': 989,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': [],\n",
       "    'tweet_id': '0x2de201',\n",
       "    'text': '\"Trust is not the same as faith. A friend is someone you trust. Putting faith in anyone is a mistake.\" ~ Christopher Hitchens <LH> <LH>'}},\n",
       "  '_crawldate': '2016-01-08 17:18:59',\n",
       "  '_type': 'tweets'},\n",
       " {'_score': 120,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': ['authentic', 'LaughOutLoud'],\n",
       "    'tweet_id': '0x1d755c',\n",
       "    'text': '@RISKshow @TheKevinAllison Thx for the BEST TIME tonight. What stories! Heartbreakingly <LH> #authentic #LaughOutLoud good!!'}},\n",
       "  '_crawldate': '2015-06-11 04:44:05',\n",
       "  '_type': 'tweets'},\n",
       " {'_score': 1021,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': [],\n",
       "    'tweet_id': '0x2c91a8',\n",
       "    'text': 'Still waiting on those supplies Liscus. <LH>'}},\n",
       "  '_crawldate': '2015-08-18 02:30:07',\n",
       "  '_type': 'tweets'},\n",
       " {'_score': 481,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': [],\n",
       "    'tweet_id': '0x368e95',\n",
       "    'text': 'Love knows no gender. 😢😭 <LH>'}},\n",
       "  '_crawldate': '2015-08-20 14:31:27',\n",
       "  '_type': 'tweets'},\n",
       " {'_score': 827,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': ['LeagueCup'],\n",
       "    'tweet_id': '0x249c0c',\n",
       "    'text': '@DStvNgCare @DStvNg More highlights are being shown than actual sports! Who watches triathlon highlights anyway? <LH> #LeagueCup'}},\n",
       "  '_crawldate': '2016-04-18 13:01:02',\n",
       "  '_type': 'tweets'},\n",
       " {'_score': 66,\n",
       "  '_index': 'hashtag_tweets',\n",
       "  '_source': {'tweet': {'hashtags': ['materialism', 'money', 'possessions'],\n",
       "    'tweet_id': '0x218443',\n",
       "    'text': 'When do you have enough ? When are you satisfied ? Is you goal really all about money ?  #materialism #money #possessions <LH>'}},\n",
       "  '_crawldate': '2015-09-09 09:22:55',\n",
       "  '_type': 'tweets'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer to dataframe\n",
    "data1 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>120</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['authentic', 'LaughOut...</td>\n",
       "      <td>2015-06-11 04:44:05</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1021</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2c91...</td>\n",
       "      <td>2015-08-18 02:30:07</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>481</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x368e...</td>\n",
       "      <td>2015-08-20 14:31:27</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>827</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['LeagueCup'], 'tweet_i...</td>\n",
       "      <td>2016-04-18 13:01:02</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['materialism', 'money'...</td>\n",
       "      <td>2015-09-09 09:22:55</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score          _index                                            _source  \\\n",
       "0     391  hashtag_tweets  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
       "1     433  hashtag_tweets  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
       "2     232  hashtag_tweets  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
       "3     376  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
       "4     989  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
       "5     120  hashtag_tweets  {'tweet': {'hashtags': ['authentic', 'LaughOut...   \n",
       "6    1021  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x2c91...   \n",
       "7     481  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x368e...   \n",
       "8     827  hashtag_tweets  {'tweet': {'hashtags': ['LeagueCup'], 'tweet_i...   \n",
       "9      66  hashtag_tweets  {'tweet': {'hashtags': ['materialism', 'money'...   \n",
       "\n",
       "            _crawldate   _type  \n",
       "0  2015-05-23 11:42:47  tweets  \n",
       "1  2016-01-28 04:52:09  tweets  \n",
       "2  2017-12-25 04:39:20  tweets  \n",
       "3  2016-01-24 23:53:05  tweets  \n",
       "4  2016-01-08 17:18:59  tweets  \n",
       "5  2015-06-11 04:44:05  tweets  \n",
       "6  2015-08-18 02:30:07  tweets  \n",
       "7  2015-08-20 14:31:27  tweets  \n",
       "8  2016-04-18 13:01:02  tweets  \n",
       "9  2015-09-09 09:22:55  tweets  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the result\n",
    "data1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only need the _source part\n",
    "data2 = pd.DataFrame(data1['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'tweet': {'hashtags': ['authentic', 'LaughOut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2c91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x368e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'tweet': {'hashtags': ['LeagueCup'], 'tweet_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'tweet': {'hashtags': ['materialism', 'money'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             _source\n",
       "0  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...\n",
       "1  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...\n",
       "2  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...\n",
       "3  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...\n",
       "4  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...\n",
       "5  {'tweet': {'hashtags': ['authentic', 'LaughOut...\n",
       "6  {'tweet': {'hashtags': [], 'tweet_id': '0x2c91...\n",
       "7  {'tweet': {'hashtags': [], 'tweet_id': '0x368e...\n",
       "8  {'tweet': {'hashtags': ['LeagueCup'], 'tweet_i...\n",
       "9  {'tweet': {'hashtags': ['materialism', 'money'..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data\n",
    "data2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of this data\n",
    "type(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the _source part to do more pre-processing\n",
    "outputpath='C:/Users/chuck/Desktop/jsondata.csv'\n",
    "data2.to_csv(outputpath,sep=',', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data_identification.csv\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "os.chdir('C:\\\\Users\\\\chuck\\\\Desktop\\\\DM2020-Lab2-Homework-main')\n",
    "fulldata = pd.read_csv('data_identification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column name\n",
    "fulldata.columns = ['tweet_id','identification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification\n",
       "0        0x28cc61           test\n",
       "1        0x29e452          train\n",
       "2        0x2b3819          train\n",
       "3        0x2db41f           test\n",
       "4        0x2a2acc          train\n",
       "...           ...            ...\n",
       "1867530  0x227e25          train\n",
       "1867531  0x293813          train\n",
       "1867532  0x1e1a7e          train\n",
       "1867533  0x2156a5          train\n",
       "1867534  0x2bb9d2          train\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data\n",
    "fulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by tweet_id\n",
    "fulldata_sort = fulldata.sort_values(by=['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1567789</th>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712459</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554555</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556552</th>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139922</th>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48334</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594176</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743351</th>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077850</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259394</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification\n",
       "1567789  0x1c7f0f           test\n",
       "712459   0x1c7f10          train\n",
       "554555   0x1c7f11          train\n",
       "1556552  0x1c7f12           test\n",
       "139922   0x1c7f13           test\n",
       "...           ...            ...\n",
       "48334    0x38fe19          train\n",
       "594176   0x38fe1a          train\n",
       "1743351  0x38fe1b           test\n",
       "1077850  0x38fe1c          train\n",
       "1259394  0x38fe1d          train\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the sort result\n",
    "fulldata_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the train part\n",
    "fulldata_sort_train = fulldata_sort[fulldata_sort['identification'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>712459</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554555</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46583</th>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737534</th>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288002</th>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657445</th>\n",
       "      <td>0x38fe18</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48334</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594176</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077850</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259394</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification\n",
       "712459   0x1c7f10          train\n",
       "554555   0x1c7f11          train\n",
       "46583    0x1c7f14          train\n",
       "737534   0x1c7f15          train\n",
       "288002   0x1c7f16          train\n",
       "...           ...            ...\n",
       "1657445  0x38fe18          train\n",
       "48334    0x38fe19          train\n",
       "594176   0x38fe1a          train\n",
       "1077850  0x38fe1c          train\n",
       "1259394  0x38fe1d          train\n",
       "\n",
       "[1455563 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check result\n",
    "fulldata_sort_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import emotion.csv\n",
    "emotion = pd.read_csv('emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column name\n",
    "emotion.columns = ['tweet_id','emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>0x38dba0</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>0x300ea2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>0x360b99</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>0x22eecf</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>0x2fb282</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id       emotion\n",
       "0        0x3140b1       sadness\n",
       "1        0x368b73       disgust\n",
       "2        0x296183  anticipation\n",
       "3        0x2bd6e1           joy\n",
       "4        0x2ee1dd  anticipation\n",
       "...           ...           ...\n",
       "1455558  0x38dba0           joy\n",
       "1455559  0x300ea2           joy\n",
       "1455560  0x360b99          fear\n",
       "1455561  0x22eecf           joy\n",
       "1455562  0x2fb282  anticipation\n",
       "\n",
       "[1455563 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data\n",
    "emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by tweet_id\n",
    "emotion_sort = emotion.sort_values(by=['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>917613</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282085</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383798</th>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466135</th>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737761</th>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775713</th>\n",
       "      <td>0x38fe18</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940737</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125961</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368544</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102332</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id       emotion\n",
       "917613   0x1c7f10           joy\n",
       "282085   0x1c7f11  anticipation\n",
       "1383798  0x1c7f14           joy\n",
       "466135   0x1c7f15           joy\n",
       "737761   0x1c7f16       disgust\n",
       "...           ...           ...\n",
       "775713   0x38fe18       sadness\n",
       "940737   0x38fe19  anticipation\n",
       "125961   0x38fe1a      surprise\n",
       "1368544  0x38fe1c       disgust\n",
       "1102332  0x38fe1d       sadness\n",
       "\n",
       "[1455563 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the sort result\n",
    "emotion_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use excel to do some pre-processing on jsondata, because the data is too large, I split to two parts\n",
    "os.chdir('C:\\\\Users\\\\chuck\\\\Desktop\\\\DM2020-Lab2-Homework-main')\n",
    "jsondata1 = pd.read_csv('jsondata_part1.csv')\n",
    "jsondata2 = pd.read_csv('jsondata_part2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>\"\"@JZED74 While inappropriate AF, he likely wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>'o m g Shut Up And Dance though #BlackMirror &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>'On #twitch &lt;LH&gt; on the #Destinybeta #Destiny ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>\"\"I tried to figure out why you mean so much t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>'The only â€œbig planâ€ you ever had in your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>0x2c7f09</td>\n",
       "      <td>'Happy where my lifeâ€™s at right now &lt;LH&gt;'}}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>0x2c7f0a</td>\n",
       "      <td>'@TNVOL_1102 @glennsolitario Had a wedding tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>0x2c7f0b</td>\n",
       "      <td>\"\"@VicOladipo Welcome to RSA. I'm coming all t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>0x2c7f0c</td>\n",
       "      <td>'@yashar @MaxineWaters @ericbolling is a sad l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>0x2c7f0d</td>\n",
       "      <td>'&lt;LH&gt; is not enough'}}\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text\n",
       "0        0x1c7f0f  \"\"@JZED74 While inappropriate AF, he likely wa...\n",
       "1        0x1c7f10  'o m g Shut Up And Dance though #BlackMirror <...\n",
       "2        0x1c7f11  'On #twitch <LH> on the #Destinybeta #Destiny ...\n",
       "3        0x1c7f12  \"\"I tried to figure out why you mean so much t...\n",
       "4        0x1c7f13  'The only â€œbig planâ€ you ever had in your ...\n",
       "...           ...                                                ...\n",
       "1048570  0x2c7f09     'Happy where my lifeâ€™s at right now <LH>'}}\"\n",
       "1048571  0x2c7f0a  '@TNVOL_1102 @glennsolitario Had a wedding tod...\n",
       "1048572  0x2c7f0b  \"\"@VicOladipo Welcome to RSA. I'm coming all t...\n",
       "1048573  0x2c7f0c  '@yashar @MaxineWaters @ericbolling is a sad l...\n",
       "1048574  0x2c7f0d                            '<LH> is not enough'}}\"\n",
       "\n",
       "[1048575 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first part\n",
    "jsondata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x2c7f0e</td>\n",
       "      <td>\"\".@JenKernsUSA Girl, don't go on #AMJoy with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2c7f0f</td>\n",
       "      <td>'Working on two Audits. &lt;LH&gt; #EALife'}}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2c7f10</td>\n",
       "      <td>'Lets show these boys how shit gets done in De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2c7f11</td>\n",
       "      <td>'Lured my Son onto the couch w/ &lt;LH&gt; &amp; #affect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2c7f12</td>\n",
       "      <td>'At work not doing shit , on twitter taking sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818955</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>'Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818956</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>'@mattmfm Fake news! &lt;LH&gt; propagated by Tumpki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818957</th>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>\"\"I told myself I'd be twitter famous. twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818958</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>'..today was brutal  ..#Hungover'}}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818959</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>'Love it when I sun burn my forehead!! NOT!! ð...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>818960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id                                               text\n",
       "0       0x2c7f0e  \"\".@JenKernsUSA Girl, don't go on #AMJoy with ...\n",
       "1       0x2c7f0f           'Working on two Audits. <LH> #EALife'}}\"\n",
       "2       0x2c7f10  'Lets show these boys how shit gets done in De...\n",
       "3       0x2c7f11  'Lured my Son onto the couch w/ <LH> & #affect...\n",
       "4       0x2c7f12  'At work not doing shit , on twitter taking sh...\n",
       "...          ...                                                ...\n",
       "818955  0x38fe19  'Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH...\n",
       "818956  0x38fe1a  '@mattmfm Fake news! <LH> propagated by Tumpki...\n",
       "818957  0x38fe1b  \"\"I told myself I'd be twitter famous. twitter...\n",
       "818958  0x38fe1c               '..today was brutal  ..#Hungover'}}\"\n",
       "818959  0x38fe1d  'Love it when I sun burn my forehead!! NOT!! ð...\n",
       "\n",
       "[818960 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second part\n",
    "jsondata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge these two parts\n",
    "jsonfull = pd.concat([jsondata1, jsondata2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>\"\"@JZED74 While inappropriate AF, he likely wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>'o m g Shut Up And Dance though #BlackMirror &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>'On #twitch &lt;LH&gt; on the #Destinybeta #Destiny ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>\"\"I tried to figure out why you mean so much t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>'The only â€œbig planâ€ you ever had in your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818955</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>'Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818956</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>'@mattmfm Fake news! &lt;LH&gt; propagated by Tumpki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818957</th>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>\"\"I told myself I'd be twitter famous. twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818958</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>'..today was brutal  ..#Hungover'}}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818959</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>'Love it when I sun burn my forehead!! NOT!! ð...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id                                               text\n",
       "0       0x1c7f0f  \"\"@JZED74 While inappropriate AF, he likely wa...\n",
       "1       0x1c7f10  'o m g Shut Up And Dance though #BlackMirror <...\n",
       "2       0x1c7f11  'On #twitch <LH> on the #Destinybeta #Destiny ...\n",
       "3       0x1c7f12  \"\"I tried to figure out why you mean so much t...\n",
       "4       0x1c7f13  'The only â€œbig planâ€ you ever had in your ...\n",
       "...          ...                                                ...\n",
       "818955  0x38fe19  'Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH...\n",
       "818956  0x38fe1a  '@mattmfm Fake news! <LH> propagated by Tumpki...\n",
       "818957  0x38fe1b  \"\"I told myself I'd be twitter famous. twitter...\n",
       "818958  0x38fe1c               '..today was brutal  ..#Hungover'}}\"\n",
       "818959  0x38fe1d  'Love it when I sun burn my forehead!! NOT!! ð...\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "jsonfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by tweet_id\n",
    "jsonfull_sort = jsonfull.sort_values(by=['tweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>\"\"@JZED74 While inappropriate AF, he likely wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>'o m g Shut Up And Dance though #BlackMirror &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>'On #twitch &lt;LH&gt; on the #Destinybeta #Destiny ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>\"\"I tried to figure out why you mean so much t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>'The only â€œbig planâ€ you ever had in your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818955</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>'Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818956</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>'@mattmfm Fake news! &lt;LH&gt; propagated by Tumpki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818957</th>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>\"\"I told myself I'd be twitter famous. twitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818958</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>'..today was brutal  ..#Hungover'}}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818959</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>'Love it when I sun burn my forehead!! NOT!! ð...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id                                               text\n",
       "0       0x1c7f0f  \"\"@JZED74 While inappropriate AF, he likely wa...\n",
       "1       0x1c7f10  'o m g Shut Up And Dance though #BlackMirror <...\n",
       "2       0x1c7f11  'On #twitch <LH> on the #Destinybeta #Destiny ...\n",
       "3       0x1c7f12  \"\"I tried to figure out why you mean so much t...\n",
       "4       0x1c7f13  'The only â€œbig planâ€ you ever had in your ...\n",
       "...          ...                                                ...\n",
       "818955  0x38fe19  'Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH...\n",
       "818956  0x38fe1a  '@mattmfm Fake news! <LH> propagated by Tumpki...\n",
       "818957  0x38fe1b  \"\"I told myself I'd be twitter famous. twitter...\n",
       "818958  0x38fe1c               '..today was brutal  ..#Hungover'}}\"\n",
       "818959  0x38fe1d  'Love it when I sun burn my forehead!! NOT!! ð...\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the sort result\n",
    "jsonfull_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column identification\n",
    "merge = pd.merge(jsonfull_sort, fulldata_sort, how='left', on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>\"\"@JZED74 While inappropriate AF, he likely wa...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>'o m g Shut Up And Dance though #BlackMirror &lt;...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>'On #twitch &lt;LH&gt; on the #Destinybeta #Destiny ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>\"\"I tried to figure out why you mean so much t...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>'The only â€œbig planâ€ you ever had in your ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>'Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>'@mattmfm Fake news! &lt;LH&gt; propagated by Tumpki...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>\"\"I told myself I'd be twitter famous. twitter...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>'..today was brutal  ..#Hungover'}}\"</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>'Love it when I sun burn my forehead!! NOT!! ð...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text  \\\n",
       "0        0x1c7f0f  \"\"@JZED74 While inappropriate AF, he likely wa...   \n",
       "1        0x1c7f10  'o m g Shut Up And Dance though #BlackMirror <...   \n",
       "2        0x1c7f11  'On #twitch <LH> on the #Destinybeta #Destiny ...   \n",
       "3        0x1c7f12  \"\"I tried to figure out why you mean so much t...   \n",
       "4        0x1c7f13  'The only â€œbig planâ€ you ever had in your ...   \n",
       "...           ...                                                ...   \n",
       "1867530  0x38fe19  'Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH...   \n",
       "1867531  0x38fe1a  '@mattmfm Fake news! <LH> propagated by Tumpki...   \n",
       "1867532  0x38fe1b  \"\"I told myself I'd be twitter famous. twitter...   \n",
       "1867533  0x38fe1c               '..today was brutal  ..#Hungover'}}\"   \n",
       "1867534  0x38fe1d  'Love it when I sun burn my forehead!! NOT!! ð...   \n",
       "\n",
       "        identification  \n",
       "0                 test  \n",
       "1                train  \n",
       "2                train  \n",
       "3                 test  \n",
       "4                 test  \n",
       "...                ...  \n",
       "1867530          train  \n",
       "1867531          train  \n",
       "1867532           test  \n",
       "1867533          train  \n",
       "1867534          train  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the train part\n",
    "merge_train = merge[merge['identification'] == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>'o m g Shut Up And Dance though #BlackMirror &lt;...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>'On #twitch &lt;LH&gt; on the #Destinybeta #Destiny ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>'A nice sunny wak this morning not many &lt;LH&gt; a...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>\"\"I'm one of those people who love candy corn....</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>'@metmuseum What are these? They look like som...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867529</th>\n",
       "      <td>0x38fe18</td>\n",
       "      <td>'@LJPBR @FifthHarmony Um  My vote For @FifthHa...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>'Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>'@mattmfm Fake news! &lt;LH&gt; propagated by Tumpki...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>'..today was brutal  ..#Hungover'}}\"</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>'Love it when I sun burn my forehead!! NOT!! ð...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text  \\\n",
       "1        0x1c7f10  'o m g Shut Up And Dance though #BlackMirror <...   \n",
       "2        0x1c7f11  'On #twitch <LH> on the #Destinybeta #Destiny ...   \n",
       "5        0x1c7f14  'A nice sunny wak this morning not many <LH> a...   \n",
       "6        0x1c7f15  \"\"I'm one of those people who love candy corn....   \n",
       "7        0x1c7f16  '@metmuseum What are these? They look like som...   \n",
       "...           ...                                                ...   \n",
       "1867529  0x38fe18  '@LJPBR @FifthHarmony Um  My vote For @FifthHa...   \n",
       "1867530  0x38fe19  'Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH...   \n",
       "1867531  0x38fe1a  '@mattmfm Fake news! <LH> propagated by Tumpki...   \n",
       "1867533  0x38fe1c               '..today was brutal  ..#Hungover'}}\"   \n",
       "1867534  0x38fe1d  'Love it when I sun burn my forehead!! NOT!! ð...   \n",
       "\n",
       "        identification  \n",
       "1                train  \n",
       "2                train  \n",
       "5                train  \n",
       "6                train  \n",
       "7                train  \n",
       "...                ...  \n",
       "1867529          train  \n",
       "1867530          train  \n",
       "1867531          train  \n",
       "1867533          train  \n",
       "1867534          train  \n",
       "\n",
       "[1455563 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "merge_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column emotion\n",
    "merge_emotion = pd.merge(merge_train, emotion_sort, how='left', on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f10</td>\n",
       "      <td>'o m g Shut Up And Dance though #BlackMirror &lt;...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x1c7f11</td>\n",
       "      <td>'On #twitch &lt;LH&gt; on the #Destinybeta #Destiny ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1c7f14</td>\n",
       "      <td>'A nice sunny wak this morning not many &lt;LH&gt; a...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f15</td>\n",
       "      <td>\"\"I'm one of those people who love candy corn....</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f16</td>\n",
       "      <td>'@metmuseum What are these? They look like som...</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>0x38fe18</td>\n",
       "      <td>'@LJPBR @FifthHarmony Um  My vote For @FifthHa...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>0x38fe19</td>\n",
       "      <td>'Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>0x38fe1a</td>\n",
       "      <td>'@mattmfm Fake news! &lt;LH&gt; propagated by Tumpki...</td>\n",
       "      <td>train</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>0x38fe1c</td>\n",
       "      <td>'..today was brutal  ..#Hungover'}}\"</td>\n",
       "      <td>train</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>0x38fe1d</td>\n",
       "      <td>'Love it when I sun burn my forehead!! NOT!! ð...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text  \\\n",
       "0        0x1c7f10  'o m g Shut Up And Dance though #BlackMirror <...   \n",
       "1        0x1c7f11  'On #twitch <LH> on the #Destinybeta #Destiny ...   \n",
       "2        0x1c7f14  'A nice sunny wak this morning not many <LH> a...   \n",
       "3        0x1c7f15  \"\"I'm one of those people who love candy corn....   \n",
       "4        0x1c7f16  '@metmuseum What are these? They look like som...   \n",
       "...           ...                                                ...   \n",
       "1455558  0x38fe18  '@LJPBR @FifthHarmony Um  My vote For @FifthHa...   \n",
       "1455559  0x38fe19  'Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH...   \n",
       "1455560  0x38fe1a  '@mattmfm Fake news! <LH> propagated by Tumpki...   \n",
       "1455561  0x38fe1c               '..today was brutal  ..#Hungover'}}\"   \n",
       "1455562  0x38fe1d  'Love it when I sun burn my forehead!! NOT!! ð...   \n",
       "\n",
       "        identification       emotion  \n",
       "0                train           joy  \n",
       "1                train  anticipation  \n",
       "2                train           joy  \n",
       "3                train           joy  \n",
       "4                train       disgust  \n",
       "...                ...           ...  \n",
       "1455558          train       sadness  \n",
       "1455559          train  anticipation  \n",
       "1455560          train      surprise  \n",
       "1455561          train       disgust  \n",
       "1455562          train       sadness  \n",
       "\n",
       "[1455563 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "merge_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the test part\n",
    "merge_test = merge[merge['identification'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x1c7f0f</td>\n",
       "      <td>\"\"@JZED74 While inappropriate AF, he likely wa...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1c7f12</td>\n",
       "      <td>\"\"I tried to figure out why you mean so much t...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1c7f13</td>\n",
       "      <td>'The only â€œbig planâ€ you ever had in your ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x1c7f17</td>\n",
       "      <td>'Looking back on situations old &amp; new, recent ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x1c7f18</td>\n",
       "      <td>'@jasoninthehouse Why do you insist on talking...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867509</th>\n",
       "      <td>0x38fe04</td>\n",
       "      <td>'\"\"The Grand Bargain\"\" The Great American Betr...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867511</th>\n",
       "      <td>0x38fe06</td>\n",
       "      <td>\"\"I get to be a 1 year old girl's new mama sta...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867524</th>\n",
       "      <td>0x38fe13</td>\n",
       "      <td>\"\"Asian dude with dangly gold earrings is back...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867525</th>\n",
       "      <td>0x38fe14</td>\n",
       "      <td>'I think @kostakoufos might be the worst playe...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x38fe1b</td>\n",
       "      <td>\"\"I told myself I'd be twitter famous. twitter...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text  \\\n",
       "0        0x1c7f0f  \"\"@JZED74 While inappropriate AF, he likely wa...   \n",
       "3        0x1c7f12  \"\"I tried to figure out why you mean so much t...   \n",
       "4        0x1c7f13  'The only â€œbig planâ€ you ever had in your ...   \n",
       "8        0x1c7f17  'Looking back on situations old & new, recent ...   \n",
       "9        0x1c7f18  '@jasoninthehouse Why do you insist on talking...   \n",
       "...           ...                                                ...   \n",
       "1867509  0x38fe04  '\"\"The Grand Bargain\"\" The Great American Betr...   \n",
       "1867511  0x38fe06  \"\"I get to be a 1 year old girl's new mama sta...   \n",
       "1867524  0x38fe13  \"\"Asian dude with dangly gold earrings is back...   \n",
       "1867525  0x38fe14  'I think @kostakoufos might be the worst playe...   \n",
       "1867532  0x38fe1b  \"\"I told myself I'd be twitter famous. twitter...   \n",
       "\n",
       "        identification  \n",
       "0                 test  \n",
       "3                 test  \n",
       "4                 test  \n",
       "8                 test  \n",
       "9                 test  \n",
       "...                ...  \n",
       "1867509           test  \n",
       "1867511           test  \n",
       "1867524           test  \n",
       "1867525           test  \n",
       "1867532           test  \n",
       "\n",
       "[411972 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "merge_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle file\n",
    "merge_emotion.to_pickle(\"train_df.pkl\") \n",
    "merge_test.to_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pickle file\n",
    "train_df = pd.read_pickle(\"train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "anger            39867\n",
       "anticipation    248935\n",
       "disgust         139101\n",
       "fear             63999\n",
       "joy             516017\n",
       "sadness         193437\n",
       "surprise         48729\n",
       "trust           205478\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group to find distribution\n",
    "train_df.groupby(['emotion']).count()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build analyzers (bag-of-words)\n",
    "BOW_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "BOW_vectorizer.fit(train_df['text'])\n",
    "\n",
    "# transform documents to document-term matrix.\n",
    "train_data_BOW_features = BOW_vectorizer.transform(train_df['text'])\n",
    "test_data_BOW_features = BOW_vectorizer.transform(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1455563x838736 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19183065 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "train_data_BOW_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data_BOW_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1monsterdown',\n",
       " '1month',\n",
       " '1monthdown',\n",
       " '1monthfacelift',\n",
       " '1monthtogo',\n",
       " '1moocat',\n",
       " '1moonstruck_me',\n",
       " '1more',\n",
       " '1moreday',\n",
       " '1moreemily',\n",
       " '1moregaryfrank',\n",
       " '1morepoint',\n",
       " '1moresem',\n",
       " '1moresleep',\n",
       " '1morestep',\n",
       " '1moretime',\n",
       " '1moreweek',\n",
       " '1morewin',\n",
       " '1moreyear',\n",
       " '1moron',\n",
       " '1most',\n",
       " '1mpbrigade',\n",
       " '1mph',\n",
       " '1mrbigshot',\n",
       " '1mrlondon',\n",
       " '1ms',\n",
       " '1muarram1439ah',\n",
       " '1muharram1439ah',\n",
       " '1must',\n",
       " '1my',\n",
       " '1mzcinnamon',\n",
       " '1nanosecond',\n",
       " '1nasty',\n",
       " '1natashastevens',\n",
       " '1nation',\n",
       " '1nationality_',\n",
       " '1nce',\n",
       " '1nd',\n",
       " '1ndone',\n",
       " '1ndus',\n",
       " '1neednewcoach',\n",
       " '1nehope',\n",
       " '1nenokkadine',\n",
       " '1never',\n",
       " '1newsfan',\n",
       " '1newsnz',\n",
       " '1nextyear',\n",
       " '1nfernoastral_',\n",
       " '1nicole_shane',\n",
       " '1nicoleromany']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe some feature names\n",
    "feature_names = BOW_vectorizer.get_feature_names()\n",
    "feature_names[10000:10050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chuck\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1455563, 500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(train_df['text'])\n",
    "\n",
    "train_data_BOW_features_500 = BOW_500.transform(train_df['text'])\n",
    "\n",
    "# check dimension\n",
    "train_data_BOW_features_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 0, 12,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 1,  2,  0, ...,  0,  0,  0],\n",
       "       [ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 4,  3,  0, ...,  0,  1,  0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_BOW_features_500.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'birthday',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'both',\n",
       " 'bring',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'can',\n",
       " 'canâ€™t',\n",
       " 'car',\n",
       " 'care',\n",
       " 'change',\n",
       " 'christ',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'coming',\n",
       " 'could',\n",
       " 'country',\n",
       " 'crazy',\n",
       " 'damn',\n",
       " 'day',\n",
       " 'days',\n",
       " 'did',\n",
       " 'dm',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'donâ€™t',\n",
       " 'down',\n",
       " 'dream',\n",
       " 'dreams',\n",
       " 'each',\n",
       " 'eat',\n",
       " 'else',\n",
       " 'end',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'eurusd',\n",
       " 'even',\n",
       " 'ever']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe some feature names\n",
    "feature_names_500 = BOW_500.get_feature_names()\n",
    "feature_names_500[100:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1455563, 500)\n",
      "y_train.shape:  (1455563,)\n",
      "X_test.shape:  (411972, 500)\n"
     ]
    }
   ],
   "source": [
    "# use DecisionTree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train = BOW_500.transform(train_df['text'])\n",
    "y_train = train_df['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(test_df['text'])\n",
    "\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# training\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_test_pred = DT_model.predict(X_test)\n",
    "\n",
    "# the pred result\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer result to dataframe\n",
    "result = pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the result and submit the answer\n",
    "outputpath='C:/Users/chuck/Desktop/result.csv'\n",
    "result.to_csv(outputpath,sep=',', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'joy' 'joy' 'joy' 'disgust' 'anticipation' 'joy' 'anticipation'\n",
      " 'sadness' 'joy']\n"
     ]
    }
   ],
   "source": [
    "# try on Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X = BOW_500.transform(train_df['text'])\n",
    "y = train_df['emotion']\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, y)\n",
    "print(clf.predict(X[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I try on DecisionTree and Naive Bayes, and DecisionTree get the better result. Which show that when the number of data attributes is large or the correlation between attributes is large, Decision Tree is better than Naive Bayes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
